{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run this cell\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from new_caller.student_caller_july.student_caller import CohortCaller\n",
    "from new_caller.student_caller_july.student_list import avocoder_toasters\n",
    "\n",
    "toaster_caller = CohortCaller(avocoder_toasters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-agreement",
   "metadata": {},
   "source": [
    "We will start this code along where we left off with yesterday's standdown activity. Below, the Titanic dataset has been loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "titanic = seaborn.load_dataset('titanic')\n",
    "titanic.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-douglas",
   "metadata": {},
   "source": [
    "Yesterday afternoon, you split the target off from the independent variables, as the cell below does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the target 'survived' off from the predictors\n",
    "X = titanic.drop('survived', axis=1)\n",
    "y = titanic['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-northeast",
   "metadata": {},
   "source": [
    "You then converted the `sex` column to a binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_female(sex_record):\n",
    "    '''\n",
    "    Transform a column indicating sex by a string\n",
    "    'male'/'female' to a binary where\n",
    "    0 = Male\n",
    "    1 = Female\n",
    "    '''\n",
    "\n",
    "    if sex_record == 'male':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "X['sex'] = X['sex'].apply(is_female)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-classroom",
   "metadata": {},
   "source": [
    "You then split the data into train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Implement a train-test split using all default arguments and random_state=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-navigation",
   "metadata": {},
   "source": [
    "Now we will use cross validation functions to select our best model.\n",
    "\n",
    "For logistic regression, it has been stressed that we need to scale our data before passing our data into `cross_validate`.  In previous exercise, we have looked the other way at this, or implemented some gnarly KFold code.  KFold is good to know, in case you do need to implement some bespoke cross validation techniques.  However, pipelines will do a lot of the same work, with a lot less code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-intelligence",
   "metadata": {},
   "source": [
    "Our first pipeline tools come from `sklearn.pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-ribbon",
   "metadata": {},
   "source": [
    "What is the difference between `Pipeline` and `make_pipeline`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-richardson",
   "metadata": {},
   "source": [
    "#Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-option",
   "metadata": {},
   "source": [
    "# Take 5 minutes with a parterner to fill in the code below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-accounting",
   "metadata": {},
   "source": [
    "To create a pipeline, we pass in different transformers and estimators. For our first pipeline, we will StandardScale our inputs, and then pass them into a LogisticRegression model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass StandardScaler and LogisticRegression objects (i.e. instances: Think parens) into make_pipeline\n",
    "pipeline = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-default",
   "metadata": {},
   "source": [
    "Below you have been provided with a function that will print out train and test scores given a pipeline and a feature_list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def print_cv_scores(pipe, feature_list):\n",
    "    \n",
    "    # we pass in pipe to cross validate along with a feature list.\n",
    "    results = cross_validate(pipe, X_train[feature_list], \n",
    "                                   y_train, \n",
    "                                   return_train_score=True)\n",
    "    \n",
    "    print(results['train_score'])\n",
    "    print(results['train_score'].mean())\n",
    "    print('##############')\n",
    "    print(results['test_score'])\n",
    "    print(results['test_score'].mean())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the pipeline above along with a list of two continuous variables: 'fare' and 'sex': "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-grocery",
   "metadata": {},
   "source": [
    "The above code ensures that the Standard Scaler and Logistic Regression model are fit only on the training sets of each fold.  There is no leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-berlin",
   "metadata": {},
   "source": [
    "# End pair task here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-playback",
   "metadata": {},
   "source": [
    "Next, we want to add some complexity to the model by adding the feature `class`.  In order to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-induction",
   "metadata": {},
   "source": [
    "In order to do so, use a OneHotEncoder to transform the column. Like our other objects, our OneHotEncoder must be fit only on the training set.  The features which it encodes may then, by chance, not include values in the test set of each fold.  If we one hot encoded before the split, this could potentially break our model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-bowling",
   "metadata": {},
   "source": [
    "Sklearn.compose has a handy class called ColumnTransformer. ColumnTransformer will allow us to pair a transformer with the columns that it should act on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-crazy",
   "metadata": {},
   "source": [
    "Create a ColumnTransformer object which takes as an argument `transformers` which equals a list of transformers.  For this instance, the list is composed of one transformer, the OneHotEncoder.  We specify the details of the transformer with a tuple that includes \n",
    " - 1: a string we create that names the transformer \n",
    " - 2: the transformer object, i.e. the OneHotEncoder object with arguments `categories=\"auto\", handle_unknown=\"ignore\"` \n",
    " - 3: a list of the feature names it acts on, in this case just `class`. \n",
    " \n",
    "The second argument after the tupple, `remainder`, describes what to do with the features not acted on by the transformer.  We want the unused features to `passthrough` to the next transformer in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-lloyd",
   "metadata": {},
   "source": [
    "# Take 5 minutes with a parterner to fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create the column transformer in this cell. \n",
    "col_transformer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-battery",
   "metadata": {},
   "source": [
    "Create a new pipeline with three arguments: col_transformer, StandardScaler(), and LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new pipeline here\n",
    "new_pipe = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cv_scores(new_pipe, ['sex', 'fare', 'class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-spotlight",
   "metadata": {},
   "source": [
    "# End pair here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-plaza",
   "metadata": {},
   "source": [
    "Run the cell below, and calculate accuracy, precision, recall, and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_hat_train = cross_val_predict(new_pipe, X_train[['sex', 'fare', 'class']], y_train)\n",
    "\n",
    "confusion_matrix(y_train, y_hat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = None\n",
    "recall = None\n",
    "precision = None\n",
    "f1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "toaster_caller.call_n_students()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-spouse",
   "metadata": {},
   "source": [
    "One great thing about pipelines is that they can be used with GridSearchCV.  That way, we can try out different combinations of hyperparameters for the different objects in the pipeline.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-highway",
   "metadata": {},
   "source": [
    "We create a parameter grid which is a dictionary with keys designating the object and the hyperparameter, and values equal to a list of potential values.\n",
    "\n",
    "The tough thing to remember is the key should have the form of `objectname` + `__` + `hyperparametername`\n",
    "\n",
    "We can print out the new_pipe, like below, to see the names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-finish",
   "metadata": {},
   "source": [
    "In the cell below, create a parameter grid that tries out the values `.0001,.5,  1,50, 100` for the `C` hyperparameter.  Remember `C` equals inverse regularization strength."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-undergraduate",
   "metadata": {},
   "source": [
    "# Take 3 minutes by yourself to try this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter_grid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to fit the grid search.\n",
    "gs = GridSearchCV(pipe, parameter_grid)\n",
    "gs.fit(X_train[['sex', 'fare', 'class', 'age']], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-prefix",
   "metadata": {},
   "source": [
    "After fitting, we can access the best_score_ as well as the best_parameters, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-prophet",
   "metadata": {},
   "source": [
    "We also have the best_estimator_, which has been refit to the entire training set.  We can use that object to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell without changes\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "y_hat_train = gs.best_estimator_.predict(X_train[['sex', 'fare', 'class', 'age']])\n",
    "\n",
    "plot_confusion_matrix(gs.best_estimator_, X_train[['sex', 'fare', 'class', 'age']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = None\n",
    "precision = None\n",
    "recall = None\n",
    "f1_score = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "toaster_caller.call_n_students()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-number",
   "metadata": {},
   "source": [
    "Although there is not a huge class imbalance, let's see what effect altering the balance may have.  We could use SMOTE (caution: SMOTE only works with imblearn.pipeline objects), but here let's try altering the `class_weight`.  Create a new param_grid with that tests out the same C values above, as well as the class_weight parameters `None` and `balanced`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-printer",
   "metadata": {},
   "source": [
    "# Take 5 minutes with a partner to fill in code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parameter_grid = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-gothic",
   "metadata": {},
   "source": [
    "We can also change what metric we pass into the GridSearch via the `scoring` argument.  Pass in the string `f1` after the new_param_grid argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, new_parameter_grid, scoring=None)\n",
    "gs.fit(X_train[['sex', 'fare', 'class', 'age']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to plot the confusion matrix from the training set.\n",
    "plot_confusion_matrix(gs.best_estimator_, X_train[['sex', 'fare', 'class', 'age']], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-algeria",
   "metadata": {},
   "source": [
    "# End pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = None\n",
    "recall = None\n",
    "precision = None\n",
    "f1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "toaster_caller.call_n_students()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-semiconductor",
   "metadata": {},
   "source": [
    "Describe why the confusion matrix looks the way it does.  Why are there now less of one error and more of another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-buddy",
   "metadata": {},
   "source": [
    "# Stretch Goal\n",
    "\n",
    "Choose another classifier: KNN, NaiveBayes, DecisionTreeClassifier, and create a pipeline with it.  Use GridSearchCV to search out optimal hyperparameters for that classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-reunion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
